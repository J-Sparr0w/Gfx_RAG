{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (0.3.20)\n",
      "Requirement already satisfied: tiktoken in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: langchain_ollama in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: langchainhub in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: chromadb in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (0.6.3)\n",
      "Requirement already satisfied: langchain in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (0.3.21)\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_community) (0.3.46)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_community) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_community) (0.3.18)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_community) (2.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain_ollama) (0.4.7)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchainhub) (24.2)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchainhub) (2.32.0.20250306)\n",
      "Requirement already satisfied: build>=1.0.3 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (2.10.6)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (0.115.11)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (3.21.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (1.31.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: chardet in c:\\users\\archa\\appdata\\roaming\\python\\python311\\site-packages (from unstructured) (4.0.0)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Downloading lxml-5.3.1-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from unstructured) (4.13.3)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 981.5/981.5 kB 15.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.12.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: backoff in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from unstructured) (2.2.1)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.31.3-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wrapt in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from unstructured) (1.17.2)\n",
      "Requirement already satisfied: psutil in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from unstructured) (5.9.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: html5lib in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: pyproject_hooks in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.46.1)\n",
      "Requirement already satisfied: anyio in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\archa\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.27.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\archa\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.27.0->chromadb) (2.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: sympy in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
      "Requirement already satisfied: asgiref~=3.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: distro>=1.5.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.29.3)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from beautifulsoup4->unstructured) (2.6)\n",
      "Requirement already satisfied: webencodings in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured)\n",
      "  Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from unstructured-client->unstructured)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Downloading cffi-1.17.1-cp311-cp311-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: pyreadline3 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\sdks_and_languages\\anaconda3\\envs\\rag_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 590.6/590.6 kB 20.5 MB/s eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading lxml-5.3.1-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 2.9/3.8 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.12.2-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.31.3-py3-none-any.whl (175 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 2.6/3.2 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 13.5 MB/s eta 0:00:00\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading cffi-1.17.1-cp311-cp311-win_amd64.whl (181 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993313 sha256=54e25f1e3e5cf95b522844df6f58b0ebcbc5d60ffb9412d064e15a31483bdad4\n",
      "  Stored in directory: c:\\users\\archa\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, typing-inspection, rapidfuzz, python-magic, python-iso639, pypdf, pycparser, olefile, lxml, langdetect, joblib, eval-type-backport, emoji, aiofiles, python-oxmsg, nltk, cffi, cryptography, unstructured-client, unstructured\n",
      "Successfully installed aiofiles-24.1.0 cffi-1.17.1 cryptography-44.0.2 emoji-2.14.1 eval-type-backport-0.2.2 filetype-1.2.0 joblib-1.4.2 langdetect-1.0.9 lxml-5.3.1 nltk-3.9.1 olefile-0.47 pycparser-2.22 pypdf-5.4.0 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.12.2 typing-inspection-0.4.0 unstructured-0.17.2 unstructured-client-0.31.3\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_community tiktoken langchain_ollama langchainhub chromadb langchain unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# import bs4\n",
    "# from langchain_community.document_loaders  import WebBaseLoader\n",
    "\n",
    "# Load Documents\n",
    "# loader = WebBaseLoader(\n",
    "#     web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "#     bs_kwargs=dict(\n",
    "#         parse_only=bs4.SoupStrainer(\n",
    "#             class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "#         )\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# curr_path = os.path.abspath(os.curdir)\n",
    "# # docFileName = \"gfx101.txt\"\n",
    "# docFileName = \"gfx_pipeline.txt\" #copied till \"matrix math\", from 3d math onwards ingestion pending\n",
    "# docFilePath = os.path.join(curr_path,'docs',docFileName)\n",
    "\n",
    "# loader=TextLoader(docFilePath)\n",
    "# docs = loader.load()\n",
    "\n",
    "# print(len(docs))\n",
    "# # print(len(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Coding_Projects\\ai\\gfx_rag\\docs\\webgpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "#load webgpu\n",
    "curr_path = os.path.abspath(os.curdir)\n",
    "directory_path = os.path.join(curr_path,'docs','webgpu')\n",
    "print(directory_path)\n",
    "\n",
    "loader = DirectoryLoader(directory_path)\n",
    "docs= loader.load()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011285\n"
     ]
    }
   ],
   "source": [
    "length = 0\n",
    "for doc in docs:\n",
    "    length+=len(doc.page_content)\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName =\"llama3.2\"\n",
    "modelName =\"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 1000, chunk_overlap = 100)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print (len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding_model_name=\"nomic-embed-text\"\n",
    "vector_store = Chroma.from_documents(documents=splits,\n",
    "                                     embedding= OllamaEmbeddings(model=embedding_model_name))\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Task Decomposition for LLM agents?\"\n",
    "question = \"What happens if any of the projected point coordinates is not within this range, for instance, if x' equals -1.1?\"\n",
    "question = \"Can The Number Of Times Light Bouces off the surface of objects be infinite?\"\n",
    "question = \"What is indirect lighting\"\n",
    "question = \"Why is global illumination difficult\"\n",
    "question = \"what is 'MSAA'?\"\n",
    "question = \"Write a code for a simple histogram\"\n",
    "question = \"How to request limits\"\n",
    "question = \"What are radians?\"\n",
    "question = \"What is an orange?\"\n",
    "question = \"What is your name?\"\n",
    "# question = input('question?: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# # Multi Query: Different Perspectives\n",
    "# template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "# different versions of the given user question to retrieve relevant documents from a vector \n",
    "# database. By generating multiple perspectives on the user question, your goal is to help\n",
    "# the user overcome some of the limitations of the distance-based similarity search. \n",
    "# Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "\n",
    "# prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_ollama import ChatOllama\n",
    "\n",
    "# generate_queries = (\n",
    "#     prompt_perspectives\n",
    "#     | ChatOllama(model=modelName,temperature=0)\n",
    "#     | StrOutputParser()\n",
    "#     | (lambda x: x.split('\\n'))\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion \n",
    "    | ChatOllama(model=modelName,temperature=0)\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "retrieved_docs = retrieval_chain_rag_fusion.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.load import dumps, loads\n",
    "\n",
    "# def get_unique_union(documents: list[list]):\n",
    "#     \"\"\" Unique union of retrieved docs \"\"\"\n",
    "#     # Flatten list of lists, and convert each Document to string\n",
    "#     flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "#     # Get unique documents\n",
    "#     unique_docs = list(set(flattened_docs))\n",
    "#     # Return\n",
    "#     return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "# retrieved_docs = retrieval_chain.invoke({\"question\":question})\n",
    "# len(retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['...', 'Now that we have a buffer and 2 views we can set the data in the structure.\\n\\n```js\\n\\nconst kVelocityOffset = 0;\\n\\nconst kAccelerationOffset = 1;\\n\\nconst kFrameCountOffset = 2;\\n\\nourStructValuesAsF32[kVelocityOffset] = 1.2; ourStructValuesAsF32[kAccelerationOffset] = 3.4; ourStructValuesAsU32[kFrameCountOffset] = 56;    // an integer value ```\\n\\nLike many things in programming there are multiple ways we could set the data forOutStruct.TypedArrays have a constructor that takes various forms. For example\\n\\nnew Float32Array(12)\\n\\nThis version makes anewArrayBuffer, in this case of 12 * 4 bytes. It then creates theFloat32Arrayto view it.\\n\\nnew Float32Array([4, 5, 6])\\n\\nThis version makes anewArrayBuffer, in this case of 3 * 4 bytes. It then creates theFloat32Arrayto view it. And it sets the initial values to 4, 5, 6.\\n\\nNote you can also pass anotherTypedArray. For example\\n\\nnew Float32Array(someUint8ArrayOf6Values)will make anewArrayBufferof size 6 * 4, then create aFloat32Arrayto view it, then copy the values from the existing view into the newFloat32Array. The values are copied by number, not in binary. In other words, they are copied like this\\n\\n```js srcArray.forEach((v, i) => dstArray[i] = v); ```\\n\\nWhat does “copied by value” mean? Take this example\\n\\n```js const f32s = new Float32Array([0.8, 0.9, 1.0, 1.1, 1.2]); const u32s = new Uint32Array(f32s); console.log(u32s);   // produces 0, 0, 1, 1, 1 ```\\n\\nThe reason is you can’t put values like 0.8 and 1.2 into aUint32Array. They get converted to unsigned integers\\n\\nnew Float32Array(someArrayBuffer)', '+      // Make views into the mapped buffer. +      const uniformBufferOffset = i * uniformBufferSpace; +      const f32Offset = uniformBufferOffset / 4; +      const normalMatrixValue = uniformValues.subarray( +          f32Offset + kNormalMatrixOffset, f32Offset + kNormalMatrixOffset + 12); +      const worldValue = uniformValues.subarray( +          f32Offset + kWorldOffset, f32Offset + kWorldOffset + 16);\\n\\n// Compute a world matrix mat4.identity(worldValue); mat4.axisRotate(worldValue, axis, i + time * speed, worldValue); mat4.translate(worldValue, [0, 0, Math.sin(i * 3.721 + time * speed) * radius], worldValue); mat4.translate(worldValue, [0, 0, Math.sin(i * 9.721 + time * 0.1) * radius], worldValue); mat4.rotateX(worldValue, time * rotationSpeed + i, worldValue); mat4.scale(worldValue, [scale, scale, scale], worldValue);\\n\\n// Inverse and transpose it into the normalMatrix value mat3.fromMat4(mat4.transpose(mat4.inverse(worldValue)), normalMatrixValue);\\n\\nmathElapsedTimeMs += performance.now()\\n\\nmathTimeStartMs;\\n\\npass.setBindGroup(0, bindGroup); pass.drawIndexed(numVertices); } +    transferBuffer.unmap();\\n\\n// upload all uniform values to the uniform buffer\\n\\nif (settings.numObjects) {\\n\\nconst size = (settings.numObjects\\n\\n1)\\n\\nuniformBufferSpace + uniformBufferSize;\\n\\ndevice.queue.writeBuffer( uniformBuffer, 0, uniformValues, 0, size / uniformValues.BYTES_PER_ELEMENT);\\n\\n}\\n\\npass.end();\\n\\nconst commandBuffer = encoder.finish();\\n\\ndevice.queue.submit([commandBuffer]);\\n\\n```', '// combine the view and projection matrixes const viewProjectionMatrix = mat4.multiply(projection, viewMatrix);\\n\\n// combine the view and projection matrixes const viewProjectionMatrix = mat4.multiply(projection, viewMatrix);\\n\\nstack.save(); stack.rotateY(settings.baseRotation); stack.translate([(kDrawerSize[kWidth] * -0.5), 0, 0]); objectNdx = 0; const ctx = { pass, stack, viewProjectionMatrix }; -    drawDrawer(ctx); +    drawCabinet(ctx, kNumDrawersPerCabinet); stack.restore();\\n\\npass.end();\\n\\nconst commandBuffer = encoder.finish();\\n\\ndevice.queue.submit([commandBuffer]);\\n\\n}\\n\\n```\\n\\nAbove,drawCabinetdraws a cube the size ofkCabinetSizewhich is slightly taller than the number of cabinets we ask it to draw.\\n\\nIt then just uses the matrix stack to translate each drawer to appears at the correct position and slightly in front of the cabinet cube.\\n\\nWe didn’t have to changedrawDrawerat all. Because of the matrix stack we were able to just use it as is.\\n\\nLet’s keep going. Let’s draw multiple cabinets.\\n\\n```js const kHandleColor = [0.5, 0.5, 0.5, 1]; const kDrawerColor = [1, 1, 1, 1]; const kCabinetColor = [0.75, 0.75, 0.75, 0.75]; const kNumDrawersPerCabinet = 4; +  const kNumCabinets = 5;\\n\\nconst kDrawerSize = [40, 30, 50]; const kHandleSize = [10, 2, 2];\\n\\nconst [kWidth, kHeight, kDepth] = [0, 1, 2];\\n\\nconst kHandlePosition = [\\n\\n(kDrawerSize[kWidth]\\n\\nkHandleSize[kWidth]) / 2,\\n\\nkDrawerSize[kHeight]\\n\\n2 / 3,\\n\\nkHandleSize[kDepth],\\n\\n];', \"The pipeline above uses 1 buffer per attribute. One for position data, one for normal data, and one for texture coordinates (UVs). It culls back facing triangles, and it expects a depth texture for depth testing. All things weâ€™ve covered in other articles.\\n\\nLetâ€™s insert a few utilities for making colors and random numbers.\\n\\n```js /** Given a css color string, return an array of 4 values from 0 to 255 */ const cssColorToRGBA8 = (() => { const canvas = new OffscreenCanvas(1, 1); const ctx = canvas.getContext('2d', {willReadFrequently: true}); return cssColor => { ctx.clearRect(0, 0, 1, 1); ctx.fillStyle = cssColor; ctx.fillRect(0, 0, 1, 1); return Array.from(ctx.getImageData(0, 0, 1, 1).data); }; })();\\n\\n/** Given a css color string, return an array of 4 values from 0 to 1 */ const cssColorToRGBA = cssColor => cssColorToRGBA8(cssColor).map(v => v / 255);\\n\\n/** * Given hue, saturation, and luminance values in the range of 0 to 1 * return the corresponding CSS hsl string */ const hsl = (h, s, l) => `hsl(${h * 360 | 0}, ${s * 100}%, ${l * 100 | 0}%)`;\\n\\n/** * Given hue, saturation, and luminance values in the range of 0 to 1 * returns an array of 4 values from 0 to 1 */ const hslToRGBA = (h, s, l) => cssColorToRGBA(hsl(h, s, l));\\n\\n/** * Returns a random number between min and max. * If min and max are not specified, returns 0 to 1 * If max is not specified, return 0 to min. */ function rand(min, max) { if (min === undefined) { max = 1; min = 0; } else if (max === undefined) { max = min; min = 0; } return Math.random() * (max - min) + min; }\\n\\n/** Selects a random array element */ const randomArrayElement = arr => arr[Math.random() * arr.length | 0]; ```\\n\\nHopefully they are all pretty straight forward.\\n\\nNow letâ€™s make some textures and a sampler. Weâ€™ll use a canvas, draw an emoji on it, and then use our functioncreateTextureFromSourcethat we wrote inthe article on importing texturesto create a texture from it.\\n\\n```js const textures = [ 'ğŸ˜‚', 'ğŸ‘¾', 'ğŸ‘�', 'ğŸ‘€', 'ğŸŒ�', 'ğŸ›Ÿ', ].map(s => { const size = 128; const ctx = new OffscreenCanvas(size, size).getContext('2d'); ctx.fillStyle = '#fff'; ctx.fillRect(0, 0, size, size); ctx.font = `${size * 0.9}px sans-serif`; ctx.textAlign = 'center'; ctx.textBaseline = 'middle'; ctx.fillText(s, size / 2, size / 2); return createTextureFromSource(device, ctx.canvas, {mips: true}); });\\n\\nconst sampler = device.createSampler({\\n\\nmagFilter: 'linear',\\n\\nminFilter: 'linear',\\n\\nmipmapFilter: 'nearest',\\n\\n});\\n\\n```\\n\\nLetâ€™s create a set of material info. We havenâ€™t done this anywhere else but itâ€™s a common setup. Unity, Unreal, Blender, Three.js, Babylon,js all have a concept of amaterial. Generally, a material holds things like the color of the material, how shiny it is, as well as which texture to use, etcâ€¦\\n\\nWeâ€™ll make 20 â€œmaterialsâ€� and then pick a material at random for each cube.\", 'The signature of our main() function has been augmented with two parameters: global_id and local_id. I could have chosen any name — their value is determined by the attributes associated with them: The global_invocation_id is a built-in value that corresponds to the global x/y/z coordinates of this shader invocation in the work load. The local_invocation_id is the x/y/z coordinates of this shader vocation in the work group.', '```\\n\\nAnother example is varyings, in a vertex shader you usevarying vec2 v_texcoordorout vec2 v_texcoordand in the fragment shader you declare the corresponding varying naming itv_texcoord. The good part of this is if you mistype the name youâ€™ll get an error.', \"magFilter: 'linear',\\n\\nminFilter: 'linear',\\n\\nmipmapFilter: 'nearest',\\n\\n});\\n\\n```\\n\\nLetâ€™s create a set of material info. We havenâ€™t done this anywhere else but itâ€™s a common setup. Unity, Unreal, Blender, Three.js, Babylon,js all have a concept of amaterial. Generally, a material holds things like the color of the material, how shiny it is, as well as which texture to use, etcâ€¦\\n\\nWeâ€™ll make 20 â€œmaterialsâ€� and then pick a material at random for each cube.\", 'formatis similar tofragment.targets[?].format. It’s the format of the depth texture we will use. The available depth texture formats were listedin the article on textures.depth24plusis a good default format to choose.\\n\\nWe also need to update our render pass descriptor so it has a depth stencil attachment.', 'Select a finger and just â€˜rotation xâ€™ and youâ€™ll see the segments further down all rotate with it.\\n\\nAnother advantage of a scene graph is that you can easily ask for the position and orientation of any node in the graph.\\n\\nSo, to shoot a from the index finger we need to know the node for the tip of the finger.\\n\\nMany scene graph APIs have functions to find nodes by name. Letâ€™s add one to ours.\\n\\n```js\\n\\nclass SceneGraphNode {\\n\\nconstructor(name, source) {\\n\\nthis.name = name;', \"function render() { const encoder = device.createCommandEncoder({ label: 'clear encoder' }); const canvasTexture = context.getCurrentTexture(); renderPassDescriptor.colorAttachments[0].view = canvasTexture.createView();\\n\\nconst pass = encoder.beginRenderPass(renderPassDescriptor);\\n\\npass.end();\\n\\nconst commandBuffer = encoder.finish();\\n\\ndevice.queue.submit([commandBuffer]);\\n\\n}\\n\\nconst observer = new ResizeObserver(entries => { for (const entry of entries) { const canvas = entry.target; const width = entry.contentBoxSize[0].inlineSize; const height = entry.contentBoxSize[0].blockSize; canvas.width = Math.max(1, Math.min(width, device.limits.maxTextureDimension2D)); canvas.height = Math.max(1, Math.min(height, device.limits.maxTextureDimension2D)); render(); } }); observer.observe(canvas); } ```\\n\\nLetâ€™s also set the canvasâ€™s CSS background to a gray checkerboard\\n\\n```css canvas { background-color: #404040; background-image: linear-gradient(45deg, #808080 25%, transparent 25%), linear-gradient(-45deg, #808080 25%, transparent 25%), linear-gradient(45deg, transparent 75%, #808080 75%), linear-gradient(-45deg, transparent 75%, #808080 75%); background-size: 32px 32px; background-position: 0 0, 0 16px, 16px -16px, -16px 0px; } ```\\n\\nTo that letâ€™s add a UI so we can set the alpha and color of the clear value as well as whether or not itâ€™s premultiplied\\n\\n```js\\n\\n+import GUI from '../3rdparty/muigui\\n\\n0.x.module.js';\\n\\n...\", 'by using instancing. For other models, itâ€™s arguably less common.', 'Note that you can use this type of “aim” math for more than just cameras. Common uses are making a character’s head follow some target.  Making a turret aim at a target.  Making an object follow a path.  You compute where on the path the target is.  Then you compute where on the path the target would be a few moments in the future.  Plug those 2 values into youraimfunction and you’ll get a matrix that makes your object follow the path and orient toward the path as well.', '+              }, +            }, }, ], }, }); ```', \"Why's it called orthographic projectionOrthographic in this case comes from the word,orthogonalorthogonaladjective:of or involving right angles\\n\\nOrthographic in this case comes from the word,orthogonal\\n\\nadjective:\\n\\nit’s possible with creative arrangement of the indices we could use@interpolate(flat)as mentioned inthe article on inter-stage variablesand still use indices.↩︎\\n\\nit’s possible with creative arrangement of the indices we could use@interpolate(flat)as mentioned inthe article on inter-stage variablesand still use indices.↩︎\", \"So, first we create a query set.\\n\\n```js\\n\\nconst querySet = device.createQuerySet({\\n\\ntype: 'timestamp',\\n\\ncount: 2,\\n\\n});\\n\\n```\\n\\nWe need count to be at least 2 so we can write both a start and end timestamp.\\n\\nWe need a buffer to convert the querySet info into data we can access.\\n\\n```js\\n\\nconst resolveBuffer = device.createBuffer({\\n\\nsize: querySet.count\\n\\n8,\\n\\nusage: GPUBufferUsage.QUERY_RESOLVE | GPUBufferUsage.COPY_SRC,\\n\\n});\\n\\n```\", 'Here are all the examples above running live in case you find it useful to play around with them to understand them.', 'I’m a little bit worried these articles will be boring at first. Feel free to jump around if you’d like. Just remember if you don’t understand something you probably need to read or review these basics. Once we get the basics down, we’ll start going over actual techniques.\\n\\nOne other thing. All of the example programs can be edited live in the webpage. Further, they can all easily be exported tojsfiddleandcodepenand evenstackoverflow. Just click “Export”.', 'Instead we need to add perspective. Just what is perspective? It’s basically the feature that things that are further away appear smaller.\\n\\nLooking at the example above we see that things further away are drawn smaller. Given our current sample one easy way to make it so that things that are further away appear smaller would be to divide the clip space X and Y by Z.', 'It’s a tiny change to generate all 4 at once.\\n\\nIn JavaScript, here’s the changes to generate 4 histograms at once\\n\\n```js function computeHistogram(numBins, imgData) { const {width, height, data} = imgData; -  const bins = new Array(numBins).fill(0); +  const bins = new Array(numBins * 4).fill(0); for (let y = 0; y < height; ++y) { for (let x = 0; x < width; ++x) { const offset = (y * width + x) * 4;\\n\\nconst r = data[offset + 0] / 255;\\n\\nconst g = data[offset + 1] / 255;', \"}], +      targets: [ +        { +         format: presentationFormat, +          blend: { +            color: { +              srcFactor: 'one', +              dstFactor: 'one-minus-src-alpha', +              operation: 'add', +            }, +            alpha: { +              srcFactor: 'one', +              dstFactor: 'one-minus-src-alpha', +              operation: 'add', +            }, +          }, +        }, +      ], }, }); ```\", \"you decide whether the result of that positive or negative? That's the land ofimaginary numbers.\", '}\\n\\n+      processShots(now, deltaTime); } ```\\n\\nWe need to keep running if there are shots. When the â€˜Fire!â€™ button is pressed it will add a shot. The GUI will also callrequestRenderso it will come through this code and callprocessShots.processShotscallsrequestRenderif there are any shots and so the animation loop will continue until all shots are finished.', 'It’s not you, it’s me: To be clear, me not being able to internalize WebGL is probably a shortcoming of my own. People smarter than me have been able to build amazing stuff with WebGL (and OpenGL outside the web), but it just never really clicked for me.', \"```wgsl\\n\\nstruct Vertex {\\n\\n@location(0) position: vec2f,\\n\\n@location(1) size: f32,\\n\\n};\\n\\nstruct Uniforms {\\n\\nresolution: vec2f,\\n\\n};\\n\\nstruct VSOutput { @builtin(position) position: vec4f, +  @location(0) texcoord: vec2f, };\\n\\n@group(0) @binding(0) var<uniform> uni: Uniforms;\\n\\n@vertex fn vs( vert: Vertex, @builtin(vertex_index) vNdx: u32, ) -> VSOutput { let points = array( vec2f(-1, -1), vec2f( 1, -1), vec2f(-1,  1), vec2f(-1,  1), vec2f( 1, -1), vec2f( 1,  1), ); var vsOut: VSOutput; let pos = points[vNdx]; vsOut.position = vec4f(vert.position + pos * vert.size / uni.resolution, 0, 1); +  vsOut.texcoord = pos * 0.5 + 0.5; return vsOut; } ```\\n\\nAnd of course use a texture in the fragment shader\\n\\n```wgsl +@group(0) @binding(1) var s: sampler; +@group(0) @binding(2) var t: texture_2d<f32>;\\n\\n@fragment fn fs(vsOut: VSOutput) -> @location(0) vec4f { -  return vec4f(1, 1, 0, 1); // yellow +  return textureSample(t, s, vsOut.texcoord); } ```\\n\\nWeâ€™ll create a simple texture using a canvas like we covered inthe article on importing textures.\\n\\n```js const ctx = new OffscreenCanvas(32, 32).getContext('2d'); ctx.font = '27px sans-serif'; ctx.textAlign = 'center'; ctx.textBaseline = 'middle'; ctx.fillText('ğŸ¥‘', 16, 16);\", '...\\n\\n```\\n\\nWith that, let’s draw a single filing cabinet drawer with a handle. The drawer will be a large cube. The handle will be a small cube.', \"Next we’ll go overhow to make it have perspective.\\n\\nWhy's it called orthographic projectionOrthographic in this case comes from the word,orthogonalorthogonaladjective:of or involving right angles\\n\\nOrthographic in this case comes from the word,orthogonal\\n\\nadjective:\\n\\nit’s possible with creative arrangement of the indices we could use@interpolate(flat)as mentioned inthe article on inter-stage variablesand still use indices.↩︎\"]\n"
     ]
    }
   ],
   "source": [
    "print(len(retrieved_docs))\n",
    "print([doc.page_content for (doc,_) in retrieved_docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=modelName,\n",
    "    temperature=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "out = rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let me try to figure this out. The user has provided several HTML files and some JavaScript snippets. They're asking specifically about their JavaScript code snippet that defines a `SceneGraphNode` class.\n",
      "\n",
      "First, I'll look at the given code. It's an object with constructor parameters for `name` and `source`. Inside the constructor, it sets this.name to name and this.source to source. Then there's an edge comment saying \"Select a finger...\", which I think might be a typo or example text.\n",
      "\n",
      "I don't see any other methods in this class, so nothing stands out as special except maybe that they might have added additional methods later, but the snippet provided doesn't show those. \n",
      "\n",
      "The comment about selecting a finger and just rotating x seems like an example of how the node selection works, but again, no code here to implement that functionality.\n",
      "\n",
      "So, based on what's given, this class simply holds `name` and `source` properties without any methods. It might have been part of a larger project where they needed to select nodes in a scene graph by name or source.\n",
      "</think>\n",
      "\n",
      "The provided JavaScript snippet defines a simple `SceneGraphNode` class that stores the node's name and its origin. Here's the code:\n",
      "\n",
      "```javascript\n",
      "class SceneGraphNode {\n",
      "  constructor(name, source) {\n",
      "    this.name = name;\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "This class has two properties:\n",
      "- `name`: The identifier of the scene graph node.\n",
      "- `source`: The context or position where the node originates.\n",
      "\n",
      "The class does not include any additional functionality beyond its constructor. It could be used to track nodes in a scene graph during rendering, allowing for node selection based on their names or origins.\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
